# ğŸš€ Google Colab Kurulum Rehberi

## HÄ±zlÄ± BaÅŸlangÄ±Ã§ (3 AdÄ±m)

### 1ï¸âƒ£ GPU'yu AktifleÅŸtir
```
Colab MenÃ¼ â†’ Runtime â†’ Change runtime type â†’ GPU â†’ Save
```

### 2ï¸âƒ£ Yeni Notebook AÃ§
https://colab.research.google.com

### 3ï¸âƒ£ Bu KodlarÄ± Ã‡alÄ±ÅŸtÄ±r

#### SEÃ‡ENEK A: GitHub'dan (Ã–nerilen)
```python
# HÃ¼cre 1: Projeyi indir
!git clone https://github.com/YOUR-USERNAME/YOUR-REPO.git
%cd YOUR-REPO/whisperRealTime

# HÃ¼cre 2: BaÅŸlat
from colab_setup import quick_start_gpu
quick_start_gpu()
```

#### SEÃ‡ENEK B: Manuel Upload
```python
# HÃ¼cre 1: DosyalarÄ± yÃ¼kle
from google.colab import files
uploaded = files.upload()  # whisperRealTime.zip'i seÃ§
!unzip -q whisperRealTime.zip
%cd whisperRealTime

# HÃ¼cre 2: BaÅŸlat
from colab_setup import quick_start_gpu
quick_start_gpu()
```

## ğŸ“ Dosya HazÄ±rlama (Local'de)

```bash
# Terminal'de:
cd /Users/anilyavuz/PiyasaAnaliz
zip -r whisperRealTime.zip whisperRealTime/ \
  -x "whisperRealTime/__pycache__/*" \
  -x "whisperRealTime/.env" \
  -x "whisperRealTime/*.pyc"
```

## ğŸ¯ Model SeÃ§enekleri

### Small Model (Ã–nerilen - Dengeli)
```python
from colab_setup import quick_start_gpu
quick_start_gpu()
```

### Large-v3 Model (En Kaliteli TÃ¼rkÃ§e)
```python
from colab_setup import quick_start_large
quick_start_large()
```

### Tiny Model (CPU iÃ§in)
```python
from colab_setup import quick_start_cpu
quick_start_cpu()
```

### Ã–zel Model
```python
import os
os.environ['WHISPER_MODEL'] = 'medium'  # tiny, base, small, medium, large-v3
from colab_setup import main
main()
```

## ğŸ”§ YapÄ±landÄ±rma

### GPU KontrolÃ¼
```python
import torch
print("GPU Mevcut:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU:", torch.cuda.get_device_name(0))
    print("VRAM:", torch.cuda.get_device_properties(0).total_memory / 1024**3, "GB")
```

### ngrok Auth Token (Gerekirse)
```python
from pyngrok import ngrok
ngrok.set_auth_token("YOUR-NGROK-TOKEN")

# Sonra setup'Ä± Ã§alÄ±ÅŸtÄ±r
from colab_setup import main
main()
```

Token al: https://dashboard.ngrok.com/get-started/your-authtoken

> Ngrok token'Ä±nÄ±z olmazsa script otomatik olarak Cloudflared ile trycloudflare.com domeninde public URL Ã¼retmeye Ã§alÄ±ÅŸÄ±r.

### Cloudflared (Token gerekmez)
Script, ngrok baÅŸarÄ±sÄ±z olduÄŸunda Cloudflared binary'sini indirip tÃ¼neli otomatik aÃ§ar.
Elle denemek isterseniz:

```python
!pip install -q cloudflared
!cloudflared tunnel --url http://localhost:5123 --no-autoupdate
```

## ğŸ“Š Beklenen Ã‡Ä±ktÄ±

```
============================================================
  Faster-Whisper Realtime STT - Colab Setup
  100% ÃœCRETSIZ - GPU Destekli
============================================================
ğŸ”§ Ortam hazÄ±rlanÄ±yor...
   Python 3.10.12

ğŸ“¦ BaÄŸÄ±mlÄ±lÄ±klar yÃ¼kleniyor (bu iÅŸlem 2-3 dakika sÃ¼rebilir)...
   Installing flask>=2.3.0...
   ...
   âœ… TÃ¼m paketler yÃ¼klendi

ğŸ” GPU KontrolÃ¼...
   âœ… GPU bulundu: Tesla T4
   ğŸ“Š CUDA version: 12.2

ğŸ¤– Model YapÄ±landÄ±rmasÄ±
   âœ… Model: small
   Device: GPU

ğŸ“¥ Model indiriliyor...
   Ä°ndiriliyor: small
   âœ… Model hazÄ±r: small

ğŸŒ ngrok baÅŸlatÄ±lÄ±yor (port 5123)...
   âœ… Public URL: https://abc123.ngrok-free.app

   ğŸ“± Bu URL'i tarayÄ±cÄ±nÄ±zda aÃ§Ä±n:
   ğŸ”— https://abc123.ngrok-free.app

============================================================
  ğŸ’¡ KULLANIM TALÄ°MATLARI
============================================================

1. YukarÄ±daki Public URL'i tarayÄ±cÄ±nÄ±zda aÃ§Ä±n
2. Mikrofon iznini verin
3. 'BaÅŸlat' butonuna tÄ±klayÄ±n
4. KonuÅŸmaya baÅŸlayÄ±n!

============================================================
  Sunucu Ã§alÄ±ÅŸÄ±yor! KonuÅŸmaya baÅŸlayabilirsiniz.
============================================================

ğŸš€ Flask sunucusu baÅŸlatÄ±lÄ±yor...
   Host: 0.0.0.0
   Port: 5123
```

## â“ Sorun Giderme

### "No module named 'app'" HatasÄ±
```python
# DoÄŸru dizinde misiniz?
!pwd
!ls -la

# app.py gÃ¶rÃ¼nÃ¼yor mu?
%cd whisperRealTime
!ls app.py
```

### "CUDA out of memory" HatasÄ±
```python
# Daha kÃ¼Ã§Ã¼k model kullanÄ±n
import os
os.environ['WHISPER_MODEL'] = 'tiny'
from colab_setup import main
main()
```

### ngrok HatasÄ±
```python
# Auth token ekleyin
from pyngrok import ngrok
ngrok.set_auth_token("your-token")

# Tekrar deneyin
from colab_setup import main
main()
```

### Public URL OluÅŸmadÄ±
- Loglarda `ngrok baÅŸarÄ±sÄ±z, Cloudflared deneniyor...` mesajÄ±nÄ± gÃ¶rmÃ¼yorsanÄ±z `quick_start_gpu()` komutunu tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.
- Cloudflared log'larÄ±nda URL belirmezse Colab hÃ¼cresinde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±p tekrar deneyin:
```python
!pkill -f cloudflared || true
from colab_setup import quick_start_gpu
quick_start_gpu()
```
- HÃ¢lÃ¢ URL yoksa ngrok token'Ä±nÄ±zÄ± ekleyin veya manuel olarak `!cloudflared tunnel --url http://localhost:XXXX` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.

### "Address already in use" / Port 5123 HatasÄ±
1. Colab menÃ¼sÃ¼nden **Runtime â†’ Restart runtime** deyin ve notebook'u tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.
2. Alternatif olarak port'u deÄŸiÅŸtirin:
```python
import os
os.environ["APP_PORT"] = "6000"
from colab_setup import quick_start_gpu
quick_start_gpu()
```
3. Cloudflared Ã§alÄ±ÅŸÄ±yorsa `!pkill -f cloudflared` ile kapatÄ±p tekrar baÅŸlatÄ±n.

### Session Timeout
Colab Ã¼cretsiz tier'da ~12 saat sonra disconnect olur. Yeniden baÅŸlatmak iÃ§in:

```python
# Dosyalar hala mevcut, sadece setup'Ä± tekrar Ã§alÄ±ÅŸtÄ±rÄ±n
from colab_setup import quick_start_gpu
quick_start_gpu()
```

## ğŸ’¾ Google Drive'a Kaydet (Opsiyonel)

```python
# HÃ¼cre 1: Drive'Ä± mount et
from google.colab import drive
drive.mount('/content/drive')

# HÃ¼cre 2: DosyalarÄ± kopyala
!cp -r whisperRealTime /content/drive/MyDrive/

# Sonraki kullanÄ±mlarda:
!cp -r /content/drive/MyDrive/whisperRealTime /content/
%cd /content/whisperRealTime
from colab_setup import quick_start_gpu
quick_start_gpu()
```

## ğŸ¯ Performans Beklentileri

| Model | Ä°lk Ä°ndirme | Latency | Kalite | VRAM |
|-------|-------------|---------|--------|------|
| tiny | ~1 dakika | 500ms | Orta | ~1GB |
| small | ~2 dakika | 1-2s | Ä°yi | ~2GB |
| medium | ~5 dakika | 2-3s | YÃ¼ksek | ~5GB |
| large-v3 | ~10 dakika | 2-4s | MÃ¼kemmel | ~10GB |

**Not:** Ä°lk Ã§alÄ±ÅŸtÄ±rmada model indirilir, sonraki kullanÄ±mlarda cache'ten yÃ¼klenir (Ã§ok hÄ±zlÄ±).

## ğŸ“ Notlar

- âœ… Colab Ã¼cretsiz GPU: Tesla T4 (16GB VRAM)
- âœ… TÃ¼m modeller Ã§alÄ±ÅŸÄ±r (tiny â†’ large-v3)
- âœ… VAD otomatik aktif (Silero-VAD)
- âœ… Session ~12 saat (Ã¼cretsiz tier)
- âš ï¸ Internet gerekli (model indirme, ngrok)

## ğŸ”— Linkler

- Colab: https://colab.research.google.com
- ngrok: https://dashboard.ngrok.com
- Silero VAD: https://github.com/snakers4/silero-vad
- Faster-Whisper: https://github.com/guillaumekln/faster-whisper

---

**HazÄ±rlayan:** Faster-Whisper Realtime STT
**Tarih:** 2025
**Lisans:** Test ve EÄŸitim AmaÃ§lÄ±
